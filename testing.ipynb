{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from TDABC import *\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score,precision_score,recall_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import csv\n",
    "import seaborn as sns\n",
    "dataset = pd.DataFrame(pd.read_csv('ionosphere.csv'))\n",
    "name='ionosphere'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset[dataset.columns[1:-1]]=dataset[dataset.columns[1:-1]].replace(0,np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for var in dataset.columns[:-1]:\n",
    "    temp = dataset[dataset[var].notnull()]\n",
    "    temp = temp[[var, 'Outcome']].groupby(['Outcome'])[[var]].median().reset_index()\n",
    "    temp=np.array(temp[var])\n",
    "    print(temp)\n",
    "    dataset.loc[(dataset['Outcome'] == 0 ) & (dataset[var].isnull()), var] = temp[0]\n",
    "    dataset.loc[(dataset['Outcome'] == 1 ) & (dataset[var].isnull()), var] = temp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array(dataset)[:,:-1]\n",
    "Lab=np.array(dataset)[:,-1]\n",
    "kF = RepeatedStratifiedKFold(n_splits=10,n_repeats=5)\n",
    "matrices=[]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0.99539</th>\n",
       "      <th>-0.05889</th>\n",
       "      <th>0.85243</th>\n",
       "      <th>0.02306</th>\n",
       "      <th>0.83398</th>\n",
       "      <th>-0.37708</th>\n",
       "      <th>1.1</th>\n",
       "      <th>0.03760</th>\n",
       "      <th>...</th>\n",
       "      <th>-0.51171</th>\n",
       "      <th>0.41078</th>\n",
       "      <th>-0.46168</th>\n",
       "      <th>0.21266</th>\n",
       "      <th>-0.34090</th>\n",
       "      <th>0.42267</th>\n",
       "      <th>-0.54487</th>\n",
       "      <th>0.18641</th>\n",
       "      <th>-0.45300</th>\n",
       "      <th>g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  0  0.99539  -0.05889  0.85243  0.02306  0.83398  -0.37708      1.1  \\\n",
       "0    1  0  0.99539  -0.05889  0.85243  0.02306  0.83398  -0.37708  1.00000   \n",
       "1    1  0  1.00000  -0.18829  0.93035 -0.36156 -0.10868  -0.93597  1.00000   \n",
       "2    1  0  1.00000  -0.03365  1.00000  0.00485  1.00000  -0.12062  0.88965   \n",
       "3    1  0  1.00000  -0.45161  1.00000  1.00000  0.71216  -1.00000  0.00000   \n",
       "4    1  0  1.00000  -0.02401  0.94140  0.06531  0.92106  -0.23255  0.77152   \n",
       "..  .. ..      ...       ...      ...      ...      ...       ...      ...   \n",
       "346  1  0  0.83508   0.08298  0.73739 -0.14706  0.84349  -0.05567  0.90441   \n",
       "347  1  0  0.95113   0.00419  0.95183 -0.02723  0.93438  -0.01920  0.94590   \n",
       "348  1  0  0.94701  -0.00034  0.93207 -0.03227  0.95177  -0.03431  0.95584   \n",
       "349  1  0  0.90608  -0.01657  0.98122 -0.01989  0.95691  -0.03646  0.85746   \n",
       "350  1  0  0.84710   0.13533  0.73638 -0.06151  0.87873   0.08260  0.88928   \n",
       "\n",
       "     0.03760  ...  -0.51171  0.41078  -0.46168  0.21266  -0.34090  0.42267  \\\n",
       "0    0.03760  ...  -0.51171  0.41078  -0.46168  0.21266  -0.34090  0.42267   \n",
       "1   -0.04549  ...  -0.26569 -0.20468  -0.18401 -0.19040  -0.11593 -0.16626   \n",
       "2    0.01198  ...  -0.40220  0.58984  -0.22145  0.43100  -0.17365  0.60436   \n",
       "3    0.00000  ...   0.90695  0.51613   1.00000  1.00000  -0.20099  0.25682   \n",
       "4   -0.16399  ...  -0.65158  0.13290  -0.53206  0.02431  -0.62197 -0.05707   \n",
       "..       ...  ...       ...      ...       ...      ...       ...      ...   \n",
       "346 -0.04622  ...  -0.04202  0.83479   0.00123  1.00000   0.12815  0.86660   \n",
       "347  0.01606  ...   0.01361  0.93522   0.04925  0.93159   0.08168  0.94066   \n",
       "348  0.02446  ...   0.03193  0.92489   0.02542  0.92120   0.02242  0.92459   \n",
       "349  0.00110  ...  -0.02099  0.89147  -0.07760  0.82983  -0.17238  0.96022   \n",
       "350 -0.09139  ...  -0.15114  0.81147  -0.04822  0.78207  -0.00703  0.75747   \n",
       "\n",
       "     -0.54487  0.18641  -0.45300  g  \n",
       "0    -0.54487  0.18641  -0.45300  g  \n",
       "1    -0.06288 -0.13738  -0.02447  b  \n",
       "2    -0.24180  0.56045  -0.38238  g  \n",
       "3     1.00000 -0.32382   1.00000  b  \n",
       "4    -0.59573 -0.04608  -0.65697  g  \n",
       "..        ...      ...       ... ..  \n",
       "346  -0.10714  0.90546  -0.04307  g  \n",
       "347  -0.00035  0.91483   0.04712  g  \n",
       "348   0.00442  0.92697  -0.00577  g  \n",
       "349  -0.03757  0.87403  -0.16243  g  \n",
       "350  -0.06678  0.85764  -0.06151  g  \n",
       "\n",
       "[351 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X,Y=Benchmark(data,Lab,3,10,'A',10,0.2)\n",
    "print(accuracy_score(X,Y))\n",
    "print(confusion_matrix(X, Y,normalize='true'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [4]:\n",
    "    for mode in ['R','A','M']:    \n",
    "        real=[]\n",
    "        predicted=[]\n",
    "        for train_i, test_i in kF.split(data,Lab):\n",
    "            X_train, X_test = data[train_i], data[test_i]\n",
    "            ytrain, ytest = Lab[train_i], Lab[test_i]\n",
    "            pred=Predict3(X_train,X_test, ytrain,p,mode)\n",
    "            real=np.append(real,ytest)\n",
    "            predicted=np.append(predicted,pred)\n",
    "        confusion=confusion_matrix(real,predicted)\n",
    "        FP = confusion.sum(axis=0) - np.diag(confusion)  \n",
    "        FN = confusion.sum(axis=1) - np.diag(confusion)\n",
    "        TP = np.diag(confusion)\n",
    "        TN = confusion.sum() - (FP + FN + TP)\n",
    "        FP = FP.astype(float)\n",
    "        FN = FN.astype(float)\n",
    "        TP = TP.astype(float)\n",
    "        TN = TN.astype(float)\n",
    "        # Sensitivity, hit rate, recall, or true positive rate\n",
    "        TPR = np.mean(TP/(TP+FN))\n",
    "        # Specificity or true negative rate\n",
    "        TNR = np.mean(TN/(TN+FP)) \n",
    "        # Precision or positive predictive value\n",
    "        PPV = np.mean(TP/(TP+FP))\n",
    "        # Negative predictive value\n",
    "        NPV = np.mean(TN/(TN+FN))\n",
    "        # Fall out or false positive rate\n",
    "        FPR = np.mean(FP/(FP+TN))\n",
    "        # False negative rate\n",
    "        FNR = np.mean(FN/(TP+FN))\n",
    "        # False discovery rate\n",
    "        FDR = np.mean(FP/(TP+FP))\n",
    "        # Overall accuracy\n",
    "        ACC = np.mean((TP+TN)/(TP+FP+FN+TN))\n",
    "        F1=f1_score(real,predicted,average='macro')\n",
    "        fields=[TPR,TNR,PPV,NPV,FPR,FNR,FDR,F1,ACC,name,\"TDABC-\"+mode]\n",
    "        with open(r'comparefinal.csv', 'a+', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(fields)\n",
    "        confusion= confusion_matrix(real, predicted,normalize='true')\n",
    "        matrices.append((confusion,mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[0.96666667, 0.03333333],\n",
       "         [0.25333333, 0.74666667]]),\n",
       "  'R'),\n",
       " (array([[0.96984127, 0.03015873],\n",
       "         [0.20533333, 0.79466667]]),\n",
       "  'A'),\n",
       " (array([[0.97936508, 0.02063492],\n",
       "         [0.24888889, 0.75111111]]),\n",
       "  'M')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(matrices[2][0], annot=True, xticklabels=np.unique(Lab), yticklabels=np.unique(Lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[1.  , 0.  , 0.  ],[0.04, 0.92, 0.04],[0.14, 0.08, 0.78]]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "054b91641d605f2b4c96409402f75aafcbb4c422455cd0011e9311fe1ff952c3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
